{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Convolutional Neural Network\n",
    "\n",
    "In this exercise, you will have to create a CNN model and then train it on the CIFAR10 dataset. The data loading and model training, testing logic are already included in your code. Infact, they are the same as for the Feed Forward Neural Network you built in the last exercises.\n",
    "\n",
    "Here are the steps you need to do to complete this exercise:\n",
    "\n",
    "1. In Starter Code below, finish the `Model()` class. These should contain the code that defines the layers of your model in the `__init__()` function and the model execution in the `forward()` function.\n",
    "2. Add a cost function and optimizer. You can use the same cost functions and optimizer from the previous exercise.\n",
    "3. Run the cells to make sure that the model is training properly.\n",
    "\n",
    "In case you get stuck, you can look at the solution by clicking the jupyter symbol at the top left and navigating to `training_a_cnn_solution.ipynb`.\n",
    "\n",
    "## Try It Out!\n",
    "- Play around with the number of layers and filters in your model. How does the accuracy change? How long does it take to train the model?\n",
    "- Try to train your model with some other types of convolutional layers like depthwise separable convolutions\n",
    "- Can you create the same network in TensorFlow as well?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Installations\n",
    "**NOTE**: Everytime you start the GPU, run this before your code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time # for measuring time for testing, remove for students\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    print(\"Testing Model on Whole Testing Dataset\")\n",
    "    model.eval()\n",
    "    running_loss=0\n",
    "    running_corrects=0\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs=inputs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "    total_loss = running_loss / len(test_loader.dataset)\n",
    "    total_acc = running_corrects/ len(test_loader.dataset)\n",
    "    print(f\"Testing Accuracy: {100*total_acc}, Testing Loss: {total_loss}\")\n",
    "\n",
    "def train(model, train_loader, validation_loader, criterion, optimizer, device):\n",
    "    epochs=2\n",
    "    best_loss=1e6\n",
    "    image_dataset={'train':train_loader, 'valid':validation_loader}\n",
    "    loss_counter=0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for phase in ['train', 'valid']:\n",
    "            print(f\"Epoch {epoch}, Phase {phase}\")\n",
    "            if phase=='train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_samples=0\n",
    "\n",
    "            for step, (inputs, labels) in enumerate(image_dataset[phase]):\n",
    "                inputs=inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase=='train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data).item()\n",
    "                running_samples+=len(inputs)\n",
    "                if running_samples % 2000  == 0:\n",
    "                    accuracy = running_corrects/running_samples\n",
    "                    print(\"Images [{}/{} ({:.0f}%)] Loss: {:.2f} Accuracy: {}/{} ({:.2f}%) Time: {}\".format(\n",
    "                            running_samples,\n",
    "                            len(image_dataset[phase].dataset),\n",
    "                            100.0 * (running_samples / len(image_dataset[phase].dataset)),\n",
    "                            loss.item(),\n",
    "                            running_corrects,\n",
    "                            running_samples,\n",
    "                            100.0*accuracy,\n",
    "                            time.asctime() # for measuring time for testing, remove for students and in the formatting\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                #NOTE: Comment lines below to train and test on whole dataset\n",
    "                if running_samples>(0.2*len(image_dataset[phase].dataset)):\n",
    "                    break\n",
    "\n",
    "            epoch_loss = running_loss / running_samples\n",
    "            epoch_acc = running_corrects / running_samples\n",
    "\n",
    "            if phase=='valid':\n",
    "                if epoch_loss<best_loss:\n",
    "                    best_loss=epoch_loss\n",
    "                else:\n",
    "                    loss_counter+=1\n",
    "\n",
    "        if loss_counter==1:\n",
    "            break\n",
    "    return model\n",
    "\n",
    "# TODO: Define your model\n",
    "def create_model():\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    num_features=model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "                   nn.Linear(num_features, 10))\n",
    "    return model\n",
    "\n",
    "batch_size=10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on Device {device}\")\n",
    "\n",
    "training_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "testing_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "        download=True, transform=training_transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "        download=True, transform=testing_transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "\n",
    "model=create_model()\n",
    "model=model.to(device)\n",
    "\n",
    "# TODO: Add your cost function here\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO: Add your optimizer here\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "train(model, trainloader, testloader, criterion, optimizer, device)\n",
    "\n",
    "test(model, testloader, criterion, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
